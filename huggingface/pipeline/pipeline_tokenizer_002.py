# æ¨¡æ‹Ÿåˆ†è¯å™¨çš„ä½¿ç”¨
# å…ˆå®‰è£… pip install sentencepiece
from transformers import XLNetTokenizer

tokenizer = XLNetTokenizer.from_pretrained("xlnet/xlnet-base-cased")
results = tokenizer.tokenize("Don't you love ğŸ¤— Transformers? We sure do.")
for result in results:
    print(result)